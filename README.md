# ğŸ’¸ Insurance Charges Prediction

This project predicts individual medical insurance charges based on demographic and lifestyle factors using machine learning regression models.

---

## ğŸ“ Dataset

The dataset includes the following features:

- `age` â€” Age of the policyholder  
- `sex` â€” Gender  
- `bmi` â€” Body Mass Index  
- `children` â€” Number of dependents  
- `smoker` â€” Smoker status  
- `region` â€” Residential region  
- `charges` â€” Target variable (Insurance premium)

The dataset is available in the `data/` directory.

---

## ğŸ“Š Methodology

### ğŸ§ª Data Exploration
- View summary statistics and unique categorical values.
- Visualize distributions of key variables like age, BMI, and charges.

### ğŸ§¼ Data Preprocessing
- Handle missing values (if any).
- Encode categorical variables using one-hot encoding.
- Standardize numerical columns for uniformity.

### ğŸ¤– Model Training
Train the following regression models:
- K-Nearest Neighbors (KNN)  
- Linear Regression  
- Support Vector Machine (SVM)  
- Decision Tree Regressor  
- Random Forest Regressor

### ğŸ“ Model Evaluation
- Metric: **Mean Absolute Error (MAE)** on the test set.

---

## ğŸ“ˆ Results

| Model               | MAE        |
|---------------------|------------|
| KNN                 | 3532.65    |
| Linear Regression   | 4243.65    |
| SVM                 | 8478.46    |
| Decision Tree       | 2817.28    |
| Random Forest       | **2575.89** âœ… |

---

## ğŸ” Conclusion

- The **Random Forest Regressor** outperformed all other models with the lowest Mean Absolute Error of **2575.89**.
- Simpler models like Linear Regression and SVM were less effective for this dataset.
- Proper preprocessing (like encoding and scaling) had a significant impact on overall model performance.

---

## âš™ï¸ Tools Used

- Python  
- Pandas  
- NumPy  
- Matplotlib & Seaborn  
- Scikit-learn  
- Jupyter Notebook
